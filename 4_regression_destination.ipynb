{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Destination choice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cluster_methods\n",
    "import decisiontree_help\n",
    "import cluster_vis\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read column data\n",
    "source = \"meta/columns\"\n",
    "df_meta = pd.read_pickle(source)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare country_per_year dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from pickle\n",
    "source = \"country_data/country_per_year.pickle\"\n",
    "df_country_per_year = pd.read_pickle(source)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read number to ISO code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('meta/countrynum_to_ISO_dict.pickle', 'rb') as fp:\n",
    "    num_to_ISO = pickle.load(fp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Gallup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the 'clean_data_from18to22' pickle file from the 'gwp_data/prepared_destination' directory\n",
    "df_gwp = pd.read_pickle(\"gwp_data/prepared_destination/clean_data_from18to22_\")\n",
    "\n",
    "# Keep only rows where the value in the 'WP1325: Move Permanently to Another Country' column is 1\n",
    "df_gwp = df_gwp[df_gwp['WP1325: Move Permanently to Another Country']== 1]\n",
    "\n",
    "# Drop the 'WP1325: Move Permanently to Another Country', 'COUNTRY_ISO3: Country ISO alpha-3 code',\n",
    "# 'WP5889: Questionnaire Serial Number', and 'WP5: Country' columns from the DataFrame\n",
    "df_gwp.drop([\"WP1325: Move Permanently to Another Country\", \"COUNTRY_ISO3: Country ISO alpha-3 code\",\"WP5889: Questionnaire Serial Number\", \"WP5: Country\"], axis=1, inplace=True)\n",
    "\n",
    "# 900, 901, 902, 997, 998, 999, 903, 997, 200, 207, 133, 203, 199, 0 remove\n",
    "not_needed_index = df_gwp[df_gwp[\"WP3120: Country Would Move To\"].isin([900, 901, 902, 997, 998, 999, 903, 997, 200, 207, 133, 203, 199, 0])].index\n",
    "df_gwp.drop(not_needed_index, inplace=True)\n",
    "\n",
    "# convert numbers to ISO code\n",
    "df_gwp[\"WP3120: Country Would Move To\"] = df_gwp[\"WP3120: Country Would Move To\"].map(num_to_ISO).fillna(df_gwp[\"WP3120: Country Would Move To\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Gallup data to the country_per_year datafram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store the columns based on their categorical type\n",
    "yes_columns = []\n",
    "yn_columns = []\n",
    "ordinal_columns = []\n",
    "no_columns = []\n",
    "\n",
    "# Iterate over the columns in the df_gwp DataFrame\n",
    "for col in df_gwp.columns:\n",
    "    # Select the rows in the df_meta DataFrame that contain the current column in the \"column\" column\n",
    "    l = list(df_meta[df_meta['column'].str.contains(col)][\"categorical?\"])\n",
    "    # If a match was found in the df_meta DataFrame\n",
    "    if len(l) !=0:\n",
    "        # If the \"categorical?\" column contains \"yes\", add the column to the yes_columns list\n",
    "        if \"yes\" in l[0]:\n",
    "            yes_columns.append(col)\n",
    "        # If the \"categorical?\" column contains \"yn\", add the column to the yn_columns list\n",
    "        if \"yn\" in l[0] :\n",
    "            yn_columns.append(col)\n",
    "        # If the \"categorical?\" column contains \"ordinal\", add the column to the ordinal_columns list\n",
    "        if \"ordinal\" in l[0] :\n",
    "            ordinal_columns.append(col)\n",
    "        # If the \"categorical?\" column contains \"no\", add the column to the no_columns list\n",
    "        if \"no\" in l[0] :\n",
    "            no_columns.append(col)\n",
    "\n",
    "# Create a set of the yes_columns and yn_columns lists, and intersect it with the columns in the df_gwp DataFrame\n",
    "cat_columns = set(yn_columns + yes_columns).intersection(df_gwp.columns)\n",
    "# Remove the \"YEAR_WAVE: Wave Year\", \"WP3120: Country Would Move To\", and \"WP5889: Questionnaire Serial Number\" columns from the cat_columns set\n",
    "cat_columns = cat_columns.difference(set([\"YEAR_WAVE: Wave Year\", \"WP3120: Country Would Move To\", \"WP5889: Questionnaire Serial Number\"]))\n",
    "\n",
    "# Create a set of the ordinal_columns and no_columns lists, and intersect it with the columns in the df_gwp DataFrame\n",
    "count_columns = set(ordinal_columns + no_columns).intersection(df_gwp.columns)\n",
    "count_columns = count_columns.difference(set([\"YEAR_WAVE: Wave Year\", \"WP3120: Country Would Move To\", \"WP5889: Questionnaire Serial Number\"]))\n",
    "\n",
    "df = df_country_per_year.set_index([\"COUNTRY_ISO3: Country ISO alpha-3 code\", \"YEAR_WAVE: Wave Year\"]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dataframe\n",
    "df_help_full = pd.DataFrame()\n",
    "\n",
    "# Loop through the years\n",
    "for year in range(2016, 2022):\n",
    "    # Create a new dataframe with the data for the current year\n",
    "    df_help = pd.DataFrame()\n",
    "    df_help[\"WP3120: Country Would Move To\"] = df_gwp[df_gwp[\"YEAR_WAVE: Wave Year\"]==year][\"WP3120: Country Would Move To\"].unique()\n",
    "    df_help[\"YEAR_WAVE: Wave Year\"] = [year]* len(df_help[\"WP3120: Country Would Move To\"])\n",
    "    for col in count_columns:\n",
    "        df_help[col] = list(df_gwp[df_gwp[\"YEAR_WAVE: Wave Year\"]==year].groupby([\"WP3120: Country Would Move To\"])[col].mean())\n",
    "    for col in cat_columns:\n",
    "        mode = list(df_gwp[df_gwp[\"YEAR_WAVE: Wave Year\"]==year].groupby([\"WP3120: Country Would Move To\"])[col].apply(lambda x: x.mode() if type(x)==int else np.mean(x.mode().astype(int))))\n",
    "        df_help[col] = [x.mean() if isinstance(x, list) else x for x in mode]\n",
    "\n",
    "    # Append the data from the current year to the df_help_full dataframe\n",
    "    df_help_full = df_help_full.append(df_help, ignore_index=True)\n",
    "\n",
    "# Convert numbers to ISO code\n",
    "df_help_full[\"WP3120: Country Would Move To\"] = df_help_full[\"WP3120: Country Would Move To\"].map(num_to_ISO).fillna(df_help_full[\"WP3120: Country Would Move To\"]).astype(str)\n",
    "\n",
    "# Set the index to be the country and year columns\n",
    "df_help_full = df_help_full.set_index([\"WP3120: Country Would Move To\", \"YEAR_WAVE: Wave Year\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate popularity score for each county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store the popularity values\n",
    "dict_help = dict()\n",
    "\n",
    "# Loop through the years from 2007 to 2021\n",
    "for year in range(2007, 2022):\n",
    "    # Initialize an empty dataframe to store the data for the current year\n",
    "    df_help = pd.DataFrame()\n",
    "    # Calculate the popularity of each destination country as the number of people who selected it as a destination, divided by the total number of respondents for the year, and multiplied by 1,000,000\n",
    "    df_help['popularity'] = df_gwp[df_gwp[\"YEAR_WAVE: Wave Year\"]==year].groupby([\"WP3120: Country Would Move To\"])[\"WP3120: Country Would Move To\"].count()/df_gwp[df_gwp[\"YEAR_WAVE: Wave Year\"]==year][\"YEAR_WAVE: Wave Year\"].sum()*1000000\n",
    "\n",
    "    # Iterate over the rows in the df_help DataFrame\n",
    "    for ind, row in df_help.iterrows():\n",
    "        # Add the popularity value to the dict_help dictionary, with the destination country and year as the key\n",
    "        dict_help[(ind, year)] = row[0]\n",
    "\n",
    "# Create a set of the index values in the df DataFrame\n",
    "index_set = set(df.index)\n",
    "# Create a set of the keys in the dict_help dictionary\n",
    "dict_set = set(dict_help.keys())\n",
    "# Find the intersection of the index_set and dict_set sets\n",
    "intersect = index_set.intersection(dict_set)\n",
    "\n",
    "# Filter the df DataFrame to keep only the rows with index values in the intersect set\n",
    "df_filtered = df.drop_duplicates().loc[intersect]\n",
    "# Filter the dict_help dictionary to keep only the key-value pairs with keys in the intersect set\n",
    "filtered_dict = {k:v for (k,v) in dict_help.items() if k in intersect}\n",
    "\n",
    "# Add a 'popularity' column to the df_filtered DataFrame, mapping the filtered_dict dictionary to the index values of the DataFrame\n",
    "df_filtered[\"popularity\"] = df_filtered.index.map(filtered_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join dataframes for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the index of the df_filtered DataFrame to 'ISO'\n",
    "df_filtered = df_filtered.rename_axis(index={'COUNTRY_ISO3: Country ISO alpha-3 code': 'ISO'})\n",
    "# Rename the index of the df_help_full DataFrame to 'ISO'\n",
    "df_help_full = df_help_full.rename_axis(index={'WP3120: Country Would Move To': 'ISO'})\n",
    "# Join the df_filtered and df_help_full dataframes on the 'ISO' and 'YEAR_WAVE: Wave Year' columns\n",
    "df_joined = df_filtered.join(df_help_full, on=['ISO', 'YEAR_WAVE: Wave Year'])\n",
    "# Apply a function to the df_joined DataFrame, replacing lists with their mean values\n",
    "df_joined = df_joined.applymap(lambda x: x.mean() if type(x)==list else x)\n",
    "\n",
    "# Create a copy of the df_joined DataFrame, called df_lasso, and drop the 'freedom', 'POP', and 'logPOP' columns\n",
    "df_lasso =df_joined.copy()\n",
    "\n",
    "# Impute missing values in the df_lasso DataFrame\n",
    "df_lasso = df_lasso.fillna(df_lasso.mean())\n",
    "\n",
    "# Print the df_lasso DataFrame\n",
    "df_lasso"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression to determine coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is assigned the values of the dataframe df_lasso as a numpy array\n",
    "data = df_lasso.values\n",
    "\n",
    "# X is assigned all the columns of data except the last one, while y is assigned the last column of data\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "# Add a constant term to the predictor variables in X\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Create a linear regression model\n",
    "LR = LinearRegression()\n",
    "\n",
    "# Feature selection \n",
    "rfe = RFE(LR, n_features_to_select=35)\n",
    "\n",
    "# Fit the RFE object to the data\n",
    "rfe = rfe.fit(X, y)\n",
    "\n",
    "# Transform the data using the selected features\n",
    "X_rfe = rfe.transform(X)\n",
    "\n",
    "# Create an OLS model using y as the dependent variable and X as the predictor variables\n",
    "model = sm.OLS(y, X_rfe)\n",
    "\n",
    "# Fit the model to the data and store the results in a variable called results\n",
    "results = model.fit()\n",
    "\n",
    "# Print a summary of the model's fit to the data\n",
    "results.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight dataframe with the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of the columns to the list of predictors\n",
    "predictors = df_lasso.columns[rfe.support_]\n",
    "print(predictors)\n",
    "\n",
    "# Get the coefficients of the model, excluding the constant term, and append a value of 1 to the end of the list\n",
    "params = results.params\n",
    "\n",
    "# merge the names of the predictors with their corresponding coefficients\n",
    "coef = pd.Series(params, predictors).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='Model Coefficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of the columns to the list of predictors\n",
    "predictors = df_lasso.columns[rfe.support_]\n",
    "print(predictors)\n",
    "\n",
    "# Get the p-values\n",
    "p_values = results.pvalues\n",
    "\n",
    "# merge the names of the predictors with their corresponding coefficients\n",
    "coef = pd.Series(p_values, predictors)\n",
    "\n",
    "coef.plot(kind='bar', title='Model P-values')\n",
    "# put a line at 0.05\n",
    "plt.axhline(y=0.05, color='r', linestyle='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the df_lasso DataFrame and drop all the columns that are not in the list of predictors\n",
    "df_lasso_small = df_lasso[predictors]\n",
    "\n",
    "# Multiply all the values in the dataframe df_lasso by the values in the params list\n",
    "df_lasso_small = df_lasso_small*params\n",
    "\n",
    "# Reset the index of the dataframe\n",
    "df_lasso_small = df_lasso_small.reset_index()\n",
    "\n",
    "# Print the first 5 rows of the dataframe\n",
    "df_lasso_small.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering in year 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wyear = df_lasso_small[df_lasso_small[\"YEAR_WAVE: Wave Year\"]==2021]\n",
    "data = data_wyear.drop([ \"YEAR_WAVE: Wave Year\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of clusters with elbow method\n",
    "cluster_methods.elbow_method(data_wyear.set_index('ISO'), 2, 20, 'agglo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "clusters = cluster_methods.simple_cluster(data_wyear.set_index('ISO') , K, \"agglo\")\n",
    "c_names = list(set(clusters))\n",
    "ISO_to_num = {v:k for k,v in num_to_ISO.items()}\n",
    "\n",
    "decisiontree_help.print_clusters(num_to_ISO, c_names, clusters, list(data_wyear[\"ISO\"]))\n",
    "\n",
    "df_vis = pd.DataFrame()\n",
    "df_vis[\"WP5: Country\"] = data_wyear[\"ISO\"]\n",
    "df_vis[\"COUNTRY_ISO3: Country ISO alpha-3 code\"] = data_wyear[\"ISO\"]\n",
    "df_vis[\"cluster\"] = clusters\n",
    "\n",
    "cluster_vis.cluster_visualization(df_vis, clusters, \"decision_K6_agglo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sem-pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "041b256c5c99f7718f2c855727968e49e7d3f10987ef9aa096be837926238695"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
